{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import dgl\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.layers import Input, Dense \n",
    "from keras.models import Model\n",
    "import scipy.sparse as sp\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade jupyter ipywidgets\n",
    "# !jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess Node and Edge Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "artworks = pd.read_csv(\"/home/zhang/hajarlamtaai/KGC/PyG_data/artworks_augmented.csv\")\n",
    "properties = pd.read_csv(\"/home/zhang/hajarlamtaai/KGC/PyG_data/props.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node_features = np.arange(artworks.shape[0])\n",
    "jid_encoder = LabelEncoder()\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "artworks['JID_enc'] = jid_encoder.fit_transform(artworks['Jid'])\n",
    "artworks['label_enc'] = label_encoder.fit_transform(artworks['label'])\n",
    "\n",
    "node_features = artworks[['JID_enc', 'label_enc']].to_numpy()\n",
    "\n",
    "prop_encoder = LabelEncoder()\n",
    "properties['Prop_enc'] = prop_encoder.fit_transform(properties['Prop'])\n",
    "\n",
    "edges_src = properties['Src'].to_numpy()\n",
    "edges_dst = properties['Dest'].to_numpy()\n",
    "edge_features = properties['Prop_enc'].to_numpy()\n",
    "\n",
    "\n",
    "num_relations = len(prop_encoder.classes_)\n",
    "\n",
    "num_nodes = artworks.shape[0]\n",
    "adj_matrices = [sp.coo_matrix((np.ones(edges_src[edge_features == i].shape[0]),\n",
    "                               (edges_src[edge_features == i], edges_dst[edge_features == i])),\n",
    "                              shape=(num_nodes, num_nodes))\n",
    "                for i in range(num_relations)]\n",
    "\n",
    "node_features = node_features.astype('float32')\n",
    "adj_matrices = [sp.csr_matrix(adj).astype('float32') for adj in adj_matrices]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compressed Sparse Row (CSR) : Coords(in dense adj matrix)\tValues paires \n",
    "#Compressed Sparse column (CSC)\n",
    "#Coordinate list (COO) [2,#existingedges]\n",
    "adj_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to tf sparse tensors\n",
    "tf_adj_matrices = [tf.sparse.SparseTensor(indices=np.column_stack((adj.nonzero())),\n",
    "                                          values=adj.data,\n",
    "                                          dense_shape=adj.shape)\n",
    "                   for adj in adj_matrices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zhang/hajarlamtaai/KGC/relational-gcn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhang/miniconda3/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "# !ls relational-gcn/rgcn/layers/\n",
    "%cd relational-gcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rgcn.layers.graph import GraphConvolution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'initializations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m input_features \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m,), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m input_adj \u001b[38;5;241m=\u001b[39m [Input(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m), sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_relations)]\n\u001b[0;32m----> 5\u001b[0m graph_conv \u001b[38;5;241m=\u001b[39m \u001b[43mGraphConvolution\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_relations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_relations\u001b[49m\u001b[43m)\u001b[49m([input_features] \u001b[38;5;241m+\u001b[39m input_adj)\n\u001b[1;32m      6\u001b[0m output \u001b[38;5;241m=\u001b[39m Dense(units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m)(graph_conv)\n\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(inputs\u001b[38;5;241m=\u001b[39m[input_features] \u001b[38;5;241m+\u001b[39m input_adj, outputs\u001b[38;5;241m=\u001b[39moutput)\n",
      "File \u001b[0;32m~/hajarlamtaai/KGC/./relational-gcn/rgcn/layers/graph.py:17\u001b[0m, in \u001b[0;36mGraphConvolution.__init__\u001b[0;34m(self, output_dim, support, featureless, init, activation, weights, W_regularizer, num_bases, b_regularizer, bias, dropout, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, output_dim, support\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, featureless\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     14\u001b[0m              init\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglorot_uniform\u001b[39m\u001b[38;5;124m'\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     15\u001b[0m              weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, W_regularizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, num_bases\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     16\u001b[0m              b_regularizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit \u001b[38;5;241m=\u001b[39m  initializers\u001b[38;5;241m.\u001b[39mget(init)\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;241m=\u001b[39m activations\u001b[38;5;241m.\u001b[39mget(activation)\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dim \u001b[38;5;241m=\u001b[39m output_dim  \u001b[38;5;66;03m# number of features per node\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'initializations' is not defined"
     ]
    }
   ],
   "source": [
    "# model Definition\n",
    "input_features = Input(shape=(2,), dtype='float32')\n",
    "input_adj = [Input(shape=(None, None), sparse=True) for _ in range(num_relations)]\n",
    "\n",
    "graph_conv = GraphConvolution(output_dim=16, num_relations=num_relations)([input_features] + input_adj)\n",
    "output = Dense(units=1, activation='sigmoid')(graph_conv)\n",
    "\n",
    "model = Model(inputs=[input_features] + input_adj, outputs=output)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = node_features  # Already in shape (num_nodes, 2)\n",
    "X_adj = tf_adj_matrices\n",
    "\n",
    "# Example labels (this should be replaced with actual labels)\n",
    "y_train = np.random.randint(2, size=num_nodes)\n",
    "y_val = np.random.randint(2, size=num_nodes)\n",
    "\n",
    "# Fit the model\n",
    "model.fit([X_features] + X_adj, y_train, validation_data=([X_features] + X_adj, y_val), epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using StellarGraph implementation... \n",
    "https://github.com/stellargraph/stellargraph/blob/master/stellargraph/layer/gcn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zhang/hajarlamtaai/KGC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhang/miniconda3/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "another take on DGL library ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import dgl\n",
    "from dgl.data import DGLDataset\n",
    "import torch.nn as nn\n",
    "from dgl.nn.pytorch import RelGraphConv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "artworks = pd.read_csv(\"./PyG_data/artworks_augmented.csv\")\n",
    "properties = pd.read_csv(\"./PyG_data/props.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Jid', 'entity', 'label'], dtype='object')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artworks.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "artworks[\"Jid\"] = artworks[\"Jid\"].astype('category').cat.codes\n",
    "artwork_ids = artworks[\"Id\"].tolist()\n",
    "node_mapping = {artwork_id: idx for idx, artwork_id in enumerate(artwork_ids)}\n",
    "\n",
    "# Create edge mappings\n",
    "property_mapping = {prop: idx for idx, prop in enumerate(properties[\"Prop\"].unique())}\n",
    "properties[\"Prop_ID\"] = properties[\"Prop\"].map(property_mapping)\n",
    "\n",
    "# Map edges to node indices\n",
    "edges_src = properties[\"Src\"].map(node_mapping).to_numpy()\n",
    "edges_dst = properties[\"Dest\"].map(node_mapping).to_numpy()\n",
    "edge_features = properties[\"Prop_ID\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArtworksDataset(DGLDataset):\n",
    "    def __init__(self):\n",
    "        super().__init__(name=\"Artworks\")\n",
    "\n",
    "    def process(self):\n",
    "       \n",
    "        node_ids = torch.arange(artworks.shape[0]).long().unsqueeze(1)\n",
    "        node_jids = torch.from_numpy(artworks[\"Jid\"].to_numpy()).long().unsqueeze(1)\n",
    "        node_labels = torch.from_numpy(artworks[\"label\"].astype('category').cat.codes.to_numpy()).long().unsqueeze(1)\n",
    "        node_features = torch.cat([node_ids, node_jids, node_labels], dim=1)\n",
    "        \n",
    "        self.graph = dgl.graph((torch.from_numpy(edges_src), torch.from_numpy(edges_dst)), num_nodes=artworks.shape[0])\n",
    "        # self.graph.ndata[\"id\"] = node_features\n",
    "        # self.graph.ndata[\"jid\"] = node_jids\n",
    "        # self.graph.ndata[\"label\"] = node_labels\n",
    "        self.graph.ndata[\"feat\"] = node_features\n",
    "        self.graph.edata[\"type\"] = torch.from_numpy(edge_features).long()\n",
    "        \n",
    "        # Masks handling for link prediction task\n",
    "        n_edges = properties.shape[0]\n",
    "        n_train = int(n_edges * 0.6)\n",
    "        n_val = int(n_edges * 0.2)\n",
    "        train_mask = torch.zeros(n_edges, dtype=torch.bool)\n",
    "        val_mask = torch.zeros(n_edges, dtype=torch.bool)\n",
    "        test_mask = torch.zeros(n_edges, dtype=torch.bool)\n",
    "        train_mask[:n_train] = True\n",
    "        val_mask[n_train : n_train + n_val] = True\n",
    "        test_mask[n_train + n_val :] = True\n",
    "        self.graph.edata[\"train_mask\"] = train_mask\n",
    "        self.graph.edata[\"val_mask\"] = val_mask\n",
    "        self.graph.edata[\"test_mask\"] = test_mask\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        return self.graph\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ArtworksDataset()\n",
    "g = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=32153, num_edges=217178,\n",
       "      ndata_schemes={'feat': Scheme(shape=(3,), dtype=torch.int64)}\n",
       "      edata_schemes={'type': Scheme(shape=(), dtype=torch.int64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class RGCN(nn.Module):\n",
    "#     def __init__(self, num_nodes, h_dim, num_rels):\n",
    "#         super(RGCN, self).__init__()\n",
    "#         self.embed_id = nn.Embedding(num_nodes, h_dim)\n",
    "#         self.embed_jid = nn.Embedding(num_nodes, h_dim)\n",
    "#         self.embed_label = nn.Embedding(num_nodes, h_dim)\n",
    "#         self.conv1 = RelGraphConv(h_dim * 3, h_dim, num_rels, \"basis\", num_bases=5)\n",
    "#         self.conv2 = RelGraphConv(h_dim, h_dim, num_rels, \"basis\", num_bases=5)\n",
    "\n",
    "#     def forward(self, g, etypes):\n",
    "#         h_id = self.embed_id(g.ndata['id'])\n",
    "#         h_jid = self.embed_jid(g.ndata['jid'])\n",
    "#         h_label = self.embed_label(g.ndata['label'])\n",
    "#         h = torch.cat([h_id, h_jid, h_label], dim=1)\n",
    "#         h = self.conv1(g, h, etypes)\n",
    "#         h = torch.relu(h)\n",
    "#         h = self.conv2(g, h, etypes)\n",
    "#         return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGCN(nn.Module):\n",
    "    def __init__(self, num_nodes, input_dim, h_dim, num_rels):\n",
    "        super(RGCN, self).__init__()\n",
    "        self.conv1 = RelGraphConv(input_dim, h_dim, num_rels, \"basis\", num_bases=5)\n",
    "        self.conv2 = RelGraphConv(h_dim, h_dim, num_rels, \"basis\", num_bases=5)\n",
    "\n",
    "    def forward(self, g, etypes):\n",
    "        h = g.ndata['feat']\n",
    "        h = self.conv1(g, h, etypes)\n",
    "        h = torch.relu(h)\n",
    "        h = self.conv2(g, h, etypes)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### can we import directrly a distmult decoder ( to kinda streamline the benchmark later???)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistMultDecoder(nn.Module):\n",
    "    def __init__(self, h_dim, num_rels):\n",
    "        super(DistMultDecoder, self).__init__()\n",
    "        self.relation_emb = nn.Embedding(num_rels, h_dim)\n",
    "\n",
    "    def forward(self, h, triplets):\n",
    "        src, rel, dst = triplets[:, 0], triplets[:, 1], triplets[:, 2]\n",
    "        src_emb = h[src]\n",
    "        rel_emb = self.relation_emb(rel)\n",
    "        dst_emb = h[dst]\n",
    "        score = (src_emb * rel_emb * dst_emb).sum(dim=1)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = g.number_of_nodes()\n",
    "input_dim = 3  # id, jid, label\n",
    "num_rels = len(property_mapping)\n",
    "\n",
    "rgcn_model = RGCN(num_nodes, input_dim, 16, num_rels)\n",
    "decoder = DistMultDecoder(16, num_rels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move tensors to GPU (not working)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# g.ndata['feat'] = g.ndata['feat'].to(device)\n",
    "# g.edata['type'] = g.edata['type'].to(device)\n",
    "# g.edata['train_mask'] = g.edata['train_mask'].to(device)\n",
    "# g.edata['val_mask'] = g.edata['val_mask'].to(device)\n",
    "# g.edata['test_mask'] = g.edata['test_mask'].to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triplets(g, mask):\n",
    "    edges_src, edges_dst = g.edges()\n",
    "    src = edges_src[mask]\n",
    "    dst = edges_dst[mask]\n",
    "    rel = g.edata['type'][mask]\n",
    "    return torch.stack((src, rel, dst), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score])\n",
    "    labels = torch.cat([torch.ones(pos_score.size(0)), torch.zeros(neg_score.size(0))])\n",
    "    return nn.BCEWithLogitsLoss()(scores, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(list(rgcn_model.parameters()) + list(decoder.parameters()), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected m1 and m2 to have the same dtype, but got: long int != float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m500\u001b[39m):\n\u001b[1;32m      2\u001b[0m     rgcn_model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 3\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[43mrgcn_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     pos_triplets \u001b[38;5;241m=\u001b[39m get_triplets(g, g\u001b[38;5;241m.\u001b[39medata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_mask\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m#generate negative samples by corupting the relation\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[76], line 9\u001b[0m, in \u001b[0;36mRGCN.forward\u001b[0;34m(self, g, etypes)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, g, etypes):\n\u001b[1;32m      8\u001b[0m     h \u001b[38;5;241m=\u001b[39m g\u001b[38;5;241m.\u001b[39mndata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeat\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 9\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metypes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     h \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(h)\n\u001b[1;32m     11\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(g, h, etypes)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/dgl/nn/pytorch/conv/relgraphconv.py:183\u001b[0m, in \u001b[0;36mRelGraphConv.forward\u001b[0;34m(self, g, feat, etypes, norm, presorted)\u001b[0m\n\u001b[1;32m    181\u001b[0m g\u001b[38;5;241m.\u001b[39medata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124metype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m etypes\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# message passing\u001b[39;00m\n\u001b[0;32m--> 183\u001b[0m \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_all\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mh\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# apply bias and activation\u001b[39;00m\n\u001b[1;32m    185\u001b[0m h \u001b[38;5;241m=\u001b[39m g\u001b[38;5;241m.\u001b[39mdstdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/dgl/heterograph.py:5112\u001b[0m, in \u001b[0;36mDGLGraph.update_all\u001b[0;34m(self, message_func, reduce_func, apply_node_func, etype)\u001b[0m\n\u001b[1;32m   5110\u001b[0m _, dtid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39mmetagraph\u001b[38;5;241m.\u001b[39mfind_edge(etid)\n\u001b[1;32m   5111\u001b[0m g \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m etype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m[etype]\n\u001b[0;32m-> 5112\u001b[0m ndata \u001b[38;5;241m=\u001b[39m \u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage_passing\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapply_node_func\u001b[49m\n\u001b[1;32m   5114\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5116\u001b[0m     core\u001b[38;5;241m.\u001b[39mis_builtin(reduce_func)\n\u001b[1;32m   5117\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m reduce_func\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   5118\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m ndata\n\u001b[1;32m   5119\u001b[0m ):\n\u001b[1;32m   5120\u001b[0m     \u001b[38;5;66;03m# Replace infinity with zero for isolated nodes\u001b[39;00m\n\u001b[1;32m   5121\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ndata\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/dgl/core.py:406\u001b[0m, in \u001b[0;36mmessage_passing\u001b[0;34m(g, mfunc, rfunc, afunc)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m     orig_eid \u001b[38;5;241m=\u001b[39m g\u001b[38;5;241m.\u001b[39medata\u001b[38;5;241m.\u001b[39mget(EID, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 406\u001b[0m     msgdata \u001b[38;5;241m=\u001b[39m \u001b[43minvoke_edge_udf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mALL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanonical_etypes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morig_eid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morig_eid\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;66;03m# reduce phase\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_builtin(rfunc):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/dgl/core.py:96\u001b[0m, in \u001b[0;36minvoke_edge_udf\u001b[0;34m(graph, eid, etype, func, orig_eid)\u001b[0m\n\u001b[1;32m     87\u001b[0m dstdata \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39m_node_frames[dtid]\u001b[38;5;241m.\u001b[39msubframe(v)\n\u001b[1;32m     88\u001b[0m ebatch \u001b[38;5;241m=\u001b[39m EdgeBatch(\n\u001b[1;32m     89\u001b[0m     graph,\n\u001b[1;32m     90\u001b[0m     eid \u001b[38;5;28;01mif\u001b[39;00m orig_eid \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m orig_eid,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     94\u001b[0m     dstdata,\n\u001b[1;32m     95\u001b[0m )\n\u001b[0;32m---> 96\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mebatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/dgl/nn/pytorch/conv/relgraphconv.py:147\u001b[0m, in \u001b[0;36mRelGraphConv.message\u001b[0;34m(self, edges)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmessage\u001b[39m(\u001b[38;5;28mself\u001b[39m, edges):\n\u001b[1;32m    146\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Message function.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m     m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear_r\u001b[49m\u001b[43m(\u001b[49m\u001b[43medges\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msrc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mh\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medges\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43metype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpresorted\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnorm\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m edges\u001b[38;5;241m.\u001b[39mdata:\n\u001b[1;32m    149\u001b[0m         m \u001b[38;5;241m=\u001b[39m m \u001b[38;5;241m*\u001b[39m edges\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnorm\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/dgl/nn/pytorch/linear.py:210\u001b[0m, in \u001b[0;36mTypedLinear.forward\u001b[0;34m(self, x, x_type, sorted_by_type)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m segment_mm(x, w, seglen_a\u001b[38;5;241m=\u001b[39mseglen)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgather_mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx_b\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/dgl/ops/gather_mm.py:47\u001b[0m, in \u001b[0;36mgather_mm\u001b[0;34m(a, b, idx_b)\u001b[0m\n\u001b[1;32m     42\u001b[0m     pos_r \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[1;32m     43\u001b[0m         [pos_l[\u001b[38;5;241m1\u001b[39m:], torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;28mlen\u001b[39m(idx_b)], device\u001b[38;5;241m=\u001b[39ma\u001b[38;5;241m.\u001b[39mdevice)]\n\u001b[1;32m     44\u001b[0m     )\n\u001b[1;32m     45\u001b[0m     seglen \u001b[38;5;241m=\u001b[39m (pos_r \u001b[38;5;241m-\u001b[39m pos_l)\u001b[38;5;241m.\u001b[39mcpu()  \u001b[38;5;66;03m# XXX(minjie): cause device synchronize\u001b[39;00m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mindex_select(\n\u001b[0;32m---> 47\u001b[0m         \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msegment_mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43msorted_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseglen\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m0\u001b[39m, rev_perm\n\u001b[1;32m     48\u001b[0m     )\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mgather_mm(a, b, \u001b[38;5;28;01mNone\u001b[39;00m, idx_b)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/dgl/backend/pytorch/sparse.py:1178\u001b[0m, in \u001b[0;36msegment_mm\u001b[0;34m(A, B, seglen_A)\u001b[0m\n\u001b[1;32m   1176\u001b[0m off \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(B\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m-> 1178\u001b[0m     C\u001b[38;5;241m.\u001b[39mappend(\u001b[43mA\u001b[49m\u001b[43m[\u001b[49m\u001b[43moff\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moff\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mseglen_A\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m   1179\u001b[0m     off \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m seglen_A[i]\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m th\u001b[38;5;241m.\u001b[39mcat(C)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected m1 and m2 to have the same dtype, but got: long int != float"
     ]
    }
   ],
   "source": [
    "for epoch in range(500):\n",
    "    rgcn_model.train()\n",
    "    h = rgcn_model(g, g.edata['type'])\n",
    "    pos_triplets = get_triplets(g, g.edata['train_mask'])\n",
    "    #generate negative samples by corupting the relation\n",
    "    neg_triplets = torch.stack((pos_triplets[:, 0], torch.randint(0, num_rels, (pos_triplets.size(0),)), pos_triplets[:, 2]), dim=1) \n",
    "    pos_score = decoder(h, pos_triplets)\n",
    "    neg_score = decoder(h, neg_triplets)\n",
    "\n",
    "    loss = compute_loss(pos_score, neg_score)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        rgcn_model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_triplets = get_triplets(g, g.edata['val_mask'])\n",
    "            val_neg_triplets = torch.stack((val_triplets[:, 0], torch.randint(0, num_rels, (val_triplets.size(0),)), val_triplets[:, 2]), dim=1)\n",
    "            val_pos_score = decoder(h, val_triplets)\n",
    "            val_neg_score = decoder(h, val_neg_triplets)\n",
    "            val_loss = compute_loss(val_pos_score, val_neg_score)\n",
    "        print(f'Epoch {epoch} | Loss: {loss.item():.4f} | Val Loss: {val_loss.item():.4f}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.1646\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "rgcn_model.eval()\n",
    "with torch.no_grad():\n",
    "    h = rgcn_model(g, g.edata['type'])\n",
    "    test_triplets = get_triplets(g, g.edata['test_mask'])\n",
    "    test_neg_triplets = torch.stack((test_triplets[:, 0], torch.randint(0, num_rels, (test_triplets.size(0),)), test_triplets[:, 2]), dim=1)\n",
    "    test_pos_score = decoder(h, test_triplets)\n",
    "    test_neg_score = decoder(h, test_neg_triplets)\n",
    "    test_loss = compute_loss(test_pos_score, test_neg_score)\n",
    "print(f'Test Loss: {test_loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_model(h, src, rel=None, dst=None):\n",
    "    if rel is not None:  # Query (h, r, ?)\n",
    "        src = torch.tensor([src], device=h.device)  \n",
    "        rel = torch.tensor([rel], device=h.device) \n",
    "        src_emb = h[src]\n",
    "        rel_emb = decoder.relation_emb(rel)\n",
    "        scores = (src_emb * rel_emb * h).sum(dim=1)\n",
    "        return scores.argsort(descending=True)\n",
    "    elif dst is not None:  # Query (h, ?, t)\n",
    "        dst = torch.tensor([dst], device=h.device) \n",
    "        dst_emb = h[dst]\n",
    "        scores = (h * dst_emb).sum(dim=1)\n",
    "        return scores.argsort(descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 target nodes for (14203, 11, ?): [12107, 29524, 24271, 5461, 1801, 1947, 5591, 24907, 13969, 22563]\n",
      "Top 10 relations for (14203, ?, 5867): [18507, 4642, 5102, 25067, 11245, 1157, 21816, 16012, 11600, 28626]\n"
     ]
    }
   ],
   "source": [
    "h = rgcn_model(g, g.edata['type'])\n",
    "src_node = 14203\t\n",
    "rel_id = 11\n",
    "k = 10\n",
    "top_k = query_model(h, src_node, rel=rel_id)[:k]\n",
    "print(f'Top 10 target nodes for ({src_node}, {rel_id}, ?): {top_k.tolist()}')\n",
    "\n",
    "dst_node = 5867\n",
    "top_k_rel = query_model(h, src_node, dst=dst_node)[:k]\n",
    "print(f'Top 10 relations for ({src_node}, ?, {dst_node}): {top_k_rel.tolist()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ranks(h, triplets, model, num_nodes):\n",
    "    ranks = []\n",
    "    for i in range(triplets.shape[0]):\n",
    "        src, rel, dst = triplets[i]\n",
    "        \n",
    "        # Compute scores for all possible targets\n",
    "        src_emb = h[src].unsqueeze(0).repeat(num_nodes, 1) #(num_nodes , embedding_dim)\n",
    "        rel_emb = model.relation_emb(rel).unsqueeze(0).repeat(num_nodes, 1)  #(num_nodes , embedding_dim)\n",
    "        dst_emb = h #all node embeddings as possible destination embeddings\n",
    "        \n",
    "        scores = (src_emb * rel_emb * dst_emb).sum(dim=1)\n",
    "        \n",
    "        # Rank the correct target\n",
    "        target_score = scores[dst].item()\n",
    "        rank = (scores > target_score).sum().item() + 1\n",
    "        ranks.append(rank)\n",
    "    \n",
    "    return ranks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ranks(ranks):\n",
    "    mr = sum(ranks) / len(ranks)\n",
    "    mrr = sum(1.0 / rank for rank in ranks) / len(ranks)\n",
    "    hits_at_10 = sum(rank <= 10 for rank in ranks) / len(ranks)\n",
    "    hits_at_5 = sum(rank <= 5 for rank in ranks) / len(ranks)\n",
    "    hits_at_1 = sum(rank == 1 for rank in ranks) / len(ranks)\n",
    "    \n",
    "    return mr, mrr, hits_at_10, hits_at_5, hits_at_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MR: 3914.4604\n",
      "Test MRR: 0.1389\n",
      "Test Hits@10: 0.2941\n",
      "Test Hits@5: 0.2091\n",
      "Test Hits@1: 0.0693\n"
     ]
    }
   ],
   "source": [
    "# Testing with rank-based metrics\n",
    "rgcn_model.eval()\n",
    "with torch.no_grad():\n",
    "    h = rgcn_model(g, g.edata['type'])\n",
    "    test_triplets = get_triplets(g, g.edata['test_mask'])\n",
    "    ranks = compute_ranks(h, test_triplets, decoder, g.number_of_nodes())\n",
    "    \n",
    "    mr, mrr, hits_at_10, hits_at_5, hits_at_1 = evaluate_ranks(ranks)\n",
    "    \n",
    "    print(f'Test MR: {mr:.4f}')\n",
    "    print(f'Test MRR: {mrr:.4f}')\n",
    "    print(f'Test Hits@10: {hits_at_10:.4f}')\n",
    "    print(f'Test Hits@5: {hits_at_5:.4f}')\n",
    "    print(f'Test Hits@1: {hits_at_1:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
